{"cells":[{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import datetime\n","import os\n","import time\n","\n","import presets\n","import torch\n","import torch.utils.data\n","import torchvision\n","import torchvision.models.detection\n","import torchvision.models.detection.mask_rcnn\n","import utils\n","from coco_utils import get_coco\n","from engine import evaluate, train_one_epoch\n","from group_by_aspect_ratio import create_aspect_ratio_groups, GroupedBatchSampler\n","from torchvision.transforms import InterpolationMode\n","from transforms import SimpleCopyPaste"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import argparse\n","\n","parser = argparse.ArgumentParser(description='PyTorch Detection Testing')\n","\n","parser.add_argument(\n","    \"--dataset\",\n","    default=\"coco\",\n","    type=str,\n","    help=\"dataset name. Use coco for object detection and instance segmentation and coco_kp for Keypoint detection\",\n",")\n","parser.add_argument('--data-path', default='/home/hslee/Desktop/Datasets/COCO', help='path to dataset')\n","parser.add_argument('--test-only', action='store_true', help='only test the model')\n","parser.add_argument(\"--model\", default=\"retinanet_resnet50_fpn\", type=str, help=\"model name\")\n","parser.add_argument(\"--device\", default=\"cuda\", type=str, help=\"device (Use cuda or cpu Default: cuda)\")\n","parser.add_argument(\n","    \"-b\", \"--batch-size\", default=2, type=int, help=\"images per gpu, the total batch size is $NGPU x batch_size\"\n",")\n","parser.add_argument(\"--weights\", default=\"/home/hslee/Desktop/Embedded_AI/INU_4-1/RISE/01_pytorch-reference-retinanet/model_25.pth\", type=str, help=\"the weights enum name to load\")\n","parser.add_argument('--weights-path', default='/home/hslee/Desktop/Embedded_AI/INU_4-1/RISE/01_pytorch-reference-retinanet/model_25.pth', help='path to weights file')\n","\n","parser.add_argument(\"--backend\", default=\"PIL\", type=str.lower, help=\"PIL or tensor - case insensitive\")\n","parser.add_argument(\"--use-v2\", action=\"store_true\", help=\"Use V2 transforms\")\n","\n","args = parser.parse_args(args=[])"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# get device by using parser\n","device = torch.device(args.device)\n","print(device)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["\n","def get_dataset(is_train, args):\n","    image_set = \"train\" if is_train else \"val\"\n","    num_classes, mode = {\"coco\": (91, \"instances\"), \"coco_kp\": (2, \"person_keypoints\")}[args.dataset]\n","    with_masks = \"mask\" in args.model\n","    ds = get_coco(\n","        root=args.data_path,\n","        image_set=image_set,\n","        transforms=get_transform(is_train, args),\n","        mode=mode,\n","        use_v2=args.use_v2,\n","        with_masks=with_masks,\n","    )\n","    return ds, num_classes\n","\n","def get_transform(is_train, args):\n","    if is_train:\n","        return presets.DetectionPresetTrain(\n","            data_augmentation=args.data_augmentation, backend=args.backend, use_v2=args.use_v2\n","        )\n","    elif args.weights and args.test_only:\n","        weights = torchvision.models.get_weight(args.weights)\n","        print(weights)\n","        trans = weights.transforms()\n","        return lambda img, target: (trans(img), target)\n","    else:\n","        return presets.DetectionPresetEval(backend=args.backend, use_v2=args.use_v2)\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def get_dataset(is_train, args):\n","    image_set = \"train\" if is_train else \"val\"\n","    num_classes, mode = {\"coco\": (91, \"instances\"), \"coco_kp\": (2, \"person_keypoints\")}[args.dataset]\n","    with_masks = \"mask\" in args.model\n","    ds = get_coco(\n","        root=\"/home/hslee/Desktop/Datasets/COCO\",\n","        image_set=image_set,\n","        transforms=get_transform(is_train, args),\n","        mode=mode,\n","        with_masks=with_masks,\n","    )\n","    return ds, num_classes"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["hihihi\n","here\n","loading annotations into memory...\n","Done (t=0.21s)\n","creating index...\n","index created!\n"]}],"source":["dataset_test, _ = get_dataset(is_train=False, args=args)\n","test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n","\n","data_loader_test = torch.utils.data.DataLoader(\n","    dataset_test, batch_size=8, sampler=test_sampler, num_workers=8, collate_fn=utils.collate_fn\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hslee/anaconda3/envs/DL/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/hslee/anaconda3/envs/DL/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["reference_retinanet = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=False)\n","checkpoint = torch.load(args.weights_path)\n","\n","reference_retinanet.load_state_dict(checkpoint['model'])"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["RetinaNet(\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): FrozenBatchNorm2d(256, eps=1e-05)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(512, eps=1e-05)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (layer_blocks): ModuleList(\n","        (0-2): 3 x Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","      (extra_blocks): LastLevelP6P7(\n","        (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      )\n","    )\n","  )\n","  (anchor_generator): AnchorGenerator()\n","  (head): RetinaNetHead(\n","    (classification_head): RetinaNetClassificationHead(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","      )\n","      (cls_logits): Conv2d(256, 819, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (regression_head): RetinaNetRegressionHead(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","      )\n","      (bbox_reg): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","  )\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n",")"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["reference_retinanet.to(device)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test:  [  0/625]  eta: 0:10:03  model_time: 0.3321 (0.3321)  evaluator_time: 0.0386 (0.0386)  time: 0.9652  data: 0.5836  max mem: 5481\n","Test:  [100/625]  eta: 0:03:21  model_time: 0.3248 (0.3219)  evaluator_time: 0.0418 (0.0442)  time: 0.3865  data: 0.0079  max mem: 5852\n","Test:  [200/625]  eta: 0:02:41  model_time: 0.3259 (0.3217)  evaluator_time: 0.0406 (0.0438)  time: 0.3813  data: 0.0077  max mem: 5852\n","Test:  [300/625]  eta: 0:02:02  model_time: 0.3260 (0.3204)  evaluator_time: 0.0348 (0.0432)  time: 0.3667  data: 0.0075  max mem: 5852\n","Test:  [400/625]  eta: 0:01:24  model_time: 0.3259 (0.3204)  evaluator_time: 0.0331 (0.0434)  time: 0.3701  data: 0.0076  max mem: 5852\n","Test:  [500/625]  eta: 0:00:47  model_time: 0.3233 (0.3200)  evaluator_time: 0.0331 (0.0433)  time: 0.3644  data: 0.0081  max mem: 5852\n","Test:  [600/625]  eta: 0:00:09  model_time: 0.3235 (0.3276)  evaluator_time: 0.0381 (0.0431)  time: 0.3743  data: 0.0080  max mem: 5853\n","Test:  [624/625]  eta: 0:00:00  model_time: 0.3262 (0.3273)  evaluator_time: 0.0365 (0.0428)  time: 0.3765  data: 0.0079  max mem: 5853\n","Test: Total time: 0:04:00 (0.3841 s / it)\n","Averaged stats: model_time: 0.3262 (0.3273)  evaluator_time: 0.0365 (0.0428)\n","Accumulating evaluation results...\n","DONE (t=6.70s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.552\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.380\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.309\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.539\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.589\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n"]},{"data":{"text/plain":["<coco_eval.CocoEvaluator at 0x7fe2a8303be0>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# engine.py > def evaluate(model, data_loader, device):\n","torch.backends.cudnn.deterministic = True\n","evaluate(reference_retinanet, data_loader_test, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"DL","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
