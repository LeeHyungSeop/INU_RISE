[2024-03-20 21:11:08,565] torch.distributed.run: [WARNING] 
[2024-03-20 21:11:08,565] torch.distributed.run: [WARNING] *****************************************
[2024-03-20 21:11:08,565] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-03-20 21:11:08,565] torch.distributed.run: [WARNING] *****************************************
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(data_path='/media/data/coco', dataset='coco', model='retinanet_resnet50_fpn', device='cuda', batch_size=4, epochs=26, workers=8, opt='sgd', lr=0.01, momentum=0.9, weight_decay=0.0001, norm_weight_decay=None, lr_scheduler='multisteplr', lr_step_size=8, lr_steps=[16, 22], lr_gamma=0.1, print_freq=20, output_dir='.', resume='', start_epoch=0, aspect_ratio_group_factor=3, rpn_score_thresh=None, trainable_backbone_layers=None, data_augmentation='hflip', sync_bn=False, test_only=False, use_deterministic_algorithms=False, world_size=4, dist_url='env://', weights=None, weights_backbone='/home/hslee/INU_RISE/02_AdaptiveDepthNetwork/checkpoint/model_145.pth', amp=False, use_copypaste=False, backend='pil', use_v2=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
Loading data
loading annotations into memory...
Done (t=8.42s)
creating index...
index created!
loading annotations into memory...
Done (t=0.26s)
creating index...
index created!
Creating data loaders
Using [0, 0.5, 0.6299605249474365, 0.7937005259840997, 1.0, 1.259921049894873, 1.5874010519681991, 2.0, inf] as bins for aspect ratio quantization
Count of instances per bin: [  104   982 24236  2332  8225 74466  5763  1158]
Creating model
conv1.weight torch.Size([64, 3, 7, 7])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
layer1.0.bn1.num_batches_tracked torch.Size([])
layer1.0.conv2.weight torch.Size([64, 64, 3, 3])
layer1.0.bn2.weight torch.Size([64])
layer1.0.bn2.bias torch.Size([64])
layer1.0.bn2.running_mean torch.Size([64])
layer1.0.bn2.running_var torch.Size([64])
layer1.0.bn2.num_batches_tracked torch.Size([])
layer1.0.conv3.weight torch.Size([256, 64, 1, 1])
layer1.0.bn3.weight torch.Size([256])
layer1.0.bn3.bias torch.Size([256])
layer1.0.bn3.running_mean torch.Size([256])
layer1.0.bn3.running_var torch.Size([256])
layer1.0.bn3.num_batches_tracked torch.Size([])
layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])
layer1.0.downsample.1.weight torch.Size([256])
layer1.0.downsample.1.bias torch.Size([256])
layer1.0.downsample.1.running_mean torch.Size([256])
layer1.0.downsample.1.running_var torch.Size([256])
layer1.0.downsample.1.num_batches_tracked torch.Size([])
layer1.0.bn1_skip.weight torch.Size([64])
layer1.0.bn1_skip.bias torch.Size([64])
layer1.0.bn1_skip.running_mean torch.Size([64])
layer1.0.bn1_skip.running_var torch.Size([64])
layer1.0.bn1_skip.num_batches_tracked torch.Size([])
layer1.0.bn2_skip.weight torch.Size([64])
layer1.0.bn2_skip.bias torch.Size([64])
layer1.0.bn2_skip.running_mean torch.Size([64])
layer1.0.bn2_skip.running_var torch.Size([64])
layer1.0.bn2_skip.num_batches_tracked torch.Size([])
layer1.0.bn3_skip.weight torch.Size([256])
layer1.0.bn3_skip.bias torch.Size([256])
layer1.0.bn3_skip.running_mean torch.Size([256])
layer1.0.bn3_skip.running_var torch.Size([256])
layer1.0.bn3_skip.num_batches_tracked torch.Size([])
layer1.1.conv1.weight torch.Size([64, 256, 1, 1])
layer1.1.bn1.weight torch.Size([64])
layer1.1.bn1.bias torch.Size([64])
layer1.1.bn1.running_mean torch.Size([64])
layer1.1.bn1.running_var torch.Size([64])
layer1.1.bn1.num_batches_tracked torch.Size([])
layer1.1.conv2.weight torch.Size([64, 64, 3, 3])
layer1.1.bn2.weight torch.Size([64])
layer1.1.bn2.bias torch.Size([64])
layer1.1.bn2.running_mean torch.Size([64])
layer1.1.bn2.running_var torch.Size([64])
layer1.1.bn2.num_batches_tracked torch.Size([])
layer1.1.conv3.weight torch.Size([256, 64, 1, 1])
layer1.1.bn3.weight torch.Size([256])
layer1.1.bn3.bias torch.Size([256])
layer1.1.bn3.running_mean torch.Size([256])
layer1.1.bn3.running_var torch.Size([256])
layer1.1.bn3.num_batches_tracked torch.Size([])
layer1.1.bn1_skip.weight torch.Size([64])
layer1.1.bn1_skip.bias torch.Size([64])
layer1.1.bn1_skip.running_mean torch.Size([64])
layer1.1.bn1_skip.running_var torch.Size([64])
layer1.1.bn1_skip.num_batches_tracked torch.Size([])
layer1.1.bn2_skip.weight torch.Size([64])
layer1.1.bn2_skip.bias torch.Size([64])
layer1.1.bn2_skip.running_mean torch.Size([64])
layer1.1.bn2_skip.running_var torch.Size([64])
layer1.1.bn2_skip.num_batches_tracked torch.Size([])
layer1.1.bn3_skip.weight torch.Size([256])
layer1.1.bn3_skip.bias torch.Size([256])
layer1.1.bn3_skip.running_mean torch.Size([256])
layer1.1.bn3_skip.running_var torch.Size([256])
layer1.1.bn3_skip.num_batches_tracked torch.Size([])
layer1.2.conv1.weight torch.Size([64, 256, 1, 1])
layer1.2.bn1.weight torch.Size([64])
layer1.2.bn1.bias torch.Size([64])
layer1.2.bn1.running_mean torch.Size([64])
layer1.2.bn1.running_var torch.Size([64])
layer1.2.bn1.num_batches_tracked torch.Size([])
layer1.2.conv2.weight torch.Size([64, 64, 3, 3])
layer1.2.bn2.weight torch.Size([64])
layer1.2.bn2.bias torch.Size([64])
layer1.2.bn2.running_mean torch.Size([64])
layer1.2.bn2.running_var torch.Size([64])
layer1.2.bn2.num_batches_tracked torch.Size([])
layer1.2.conv3.weight torch.Size([256, 64, 1, 1])
layer1.2.bn3.weight torch.Size([256])
layer1.2.bn3.bias torch.Size([256])
layer1.2.bn3.running_mean torch.Size([256])
layer1.2.bn3.running_var torch.Size([256])
layer1.2.bn3.num_batches_tracked torch.Size([])
layer2.0.conv1.weight torch.Size([128, 256, 1, 1])
layer2.0.bn1.weight torch.Size([128])
layer2.0.bn1.bias torch.Size([128])
layer2.0.bn1.running_mean torch.Size([128])
layer2.0.bn1.running_var torch.Size([128])
layer2.0.bn1.num_batches_tracked torch.Size([])
layer2.0.conv2.weight torch.Size([128, 128, 3, 3])
layer2.0.bn2.weight torch.Size([128])
layer2.0.bn2.bias torch.Size([128])
layer2.0.bn2.running_mean torch.Size([128])
layer2.0.bn2.running_var torch.Size([128])
layer2.0.bn2.num_batches_tracked torch.Size([])
layer2.0.conv3.weight torch.Size([512, 128, 1, 1])
layer2.0.bn3.weight torch.Size([512])
layer2.0.bn3.bias torch.Size([512])
layer2.0.bn3.running_mean torch.Size([512])
layer2.0.bn3.running_var torch.Size([512])
layer2.0.bn3.num_batches_tracked torch.Size([])
layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])
layer2.0.downsample.1.weight torch.Size([512])
layer2.0.downsample.1.bias torch.Size([512])
layer2.0.downsample.1.running_mean torch.Size([512])
layer2.0.downsample.1.running_var torch.Size([512])
layer2.0.downsample.1.num_batches_tracked torch.Size([])
layer2.0.bn1_skip.weight torch.Size([128])
layer2.0.bn1_skip.bias torch.Size([128])
layer2.0.bn1_skip.running_mean torch.Size([128])
layer2.0.bn1_skip.running_var torch.Size([128])
layer2.0.bn1_skip.num_batches_tracked torch.Size([])
layer2.0.bn2_skip.weight torch.Size([128])
layer2.0.bn2_skip.bias torch.Size([128])
layer2.0.bn2_skip.running_mean torch.Size([128])
layer2.0.bn2_skip.running_var torch.Size([128])
layer2.0.bn2_skip.num_batches_tracked torch.Size([])
layer2.0.bn3_skip.weight torch.Size([512])
layer2.0.bn3_skip.bias torch.Size([512])
layer2.0.bn3_skip.running_mean torch.Size([512])
layer2.0.bn3_skip.running_var torch.Size([512])
layer2.0.bn3_skip.num_batches_tracked torch.Size([])
layer2.1.conv1.weight torch.Size([128, 512, 1, 1])
layer2.1.bn1.weight torch.Size([128])
layer2.1.bn1.bias torch.Size([128])
layer2.1.bn1.running_mean torch.Size([128])
layer2.1.bn1.running_var torch.Size([128])
layer2.1.bn1.num_batches_tracked torch.Size([])
layer2.1.conv2.weight torch.Size([128, 128, 3, 3])
layer2.1.bn2.weight torch.Size([128])
layer2.1.bn2.bias torch.Size([128])
layer2.1.bn2.running_mean torch.Size([128])
layer2.1.bn2.running_var torch.Size([128])
layer2.1.bn2.num_batches_tracked torch.Size([])
layer2.1.conv3.weight torch.Size([512, 128, 1, 1])
layer2.1.bn3.weight torch.Size([512])
layer2.1.bn3.bias torch.Size([512])
layer2.1.bn3.running_mean torch.Size([512])
layer2.1.bn3.running_var torch.Size([512])
layer2.1.bn3.num_batches_tracked torch.Size([])
layer2.1.bn1_skip.weight torch.Size([128])
layer2.1.bn1_skip.bias torch.Size([128])
layer2.1.bn1_skip.running_mean torch.Size([128])
layer2.1.bn1_skip.running_var torch.Size([128])
layer2.1.bn1_skip.num_batches_tracked torch.Size([])
layer2.1.bn2_skip.weight torch.Size([128])
layer2.1.bn2_skip.bias torch.Size([128])
layer2.1.bn2_skip.running_mean torch.Size([128])
layer2.1.bn2_skip.running_var torch.Size([128])
layer2.1.bn2_skip.num_batches_tracked torch.Size([])
layer2.1.bn3_skip.weight torch.Size([512])
layer2.1.bn3_skip.bias torch.Size([512])
layer2.1.bn3_skip.running_mean torch.Size([512])
layer2.1.bn3_skip.running_var torch.Size([512])
layer2.1.bn3_skip.num_batches_tracked torch.Size([])
layer2.2.conv1.weight torch.Size([128, 512, 1, 1])
layer2.2.bn1.weight torch.Size([128])
layer2.2.bn1.bias torch.Size([128])
layer2.2.bn1.running_mean torch.Size([128])
layer2.2.bn1.running_var torch.Size([128])
layer2.2.bn1.num_batches_tracked torch.Size([])
layer2.2.conv2.weight torch.Size([128, 128, 3, 3])
layer2.2.bn2.weight torch.Size([128])
layer2.2.bn2.bias torch.Size([128])
layer2.2.bn2.running_mean torch.Size([128])
layer2.2.bn2.running_var torch.Size([128])
layer2.2.bn2.num_batches_tracked torch.Size([])
layer2.2.conv3.weight torch.Size([512, 128, 1, 1])
layer2.2.bn3.weight torch.Size([512])
layer2.2.bn3.bias torch.Size([512])
layer2.2.bn3.running_mean torch.Size([512])
layer2.2.bn3.running_var torch.Size([512])
layer2.2.bn3.num_batches_tracked torch.Size([])
layer2.3.conv1.weight torch.Size([128, 512, 1, 1])
layer2.3.bn1.weight torch.Size([128])
layer2.3.bn1.bias torch.Size([128])
layer2.3.bn1.running_mean torch.Size([128])
layer2.3.bn1.running_var torch.Size([128])
layer2.3.bn1.num_batches_tracked torch.Size([])
layer2.3.conv2.weight torch.Size([128, 128, 3, 3])
layer2.3.bn2.weight torch.Size([128])
layer2.3.bn2.bias torch.Size([128])
layer2.3.bn2.running_mean torch.Size([128])
layer2.3.bn2.running_var torch.Size([128])
layer2.3.bn2.num_batches_tracked torch.Size([])
layer2.3.conv3.weight torch.Size([512, 128, 1, 1])
layer2.3.bn3.weight torch.Size([512])
layer2.3.bn3.bias torch.Size([512])
layer2.3.bn3.running_mean torch.Size([512])
layer2.3.bn3.running_var torch.Size([512])
layer2.3.bn3.num_batches_tracked torch.Size([])
layer3.0.conv1.weight torch.Size([256, 512, 1, 1])
layer3.0.bn1.weight torch.Size([256])
layer3.0.bn1.bias torch.Size([256])
layer3.0.bn1.running_mean torch.Size([256])
layer3.0.bn1.running_var torch.Size([256])
layer3.0.bn1.num_batches_tracked torch.Size([])
layer3.0.conv2.weight torch.Size([256, 256, 3, 3])
layer3.0.bn2.weight torch.Size([256])
layer3.0.bn2.bias torch.Size([256])
layer3.0.bn2.running_mean torch.Size([256])
layer3.0.bn2.running_var torch.Size([256])
layer3.0.bn2.num_batches_tracked torch.Size([])
layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])
layer3.0.bn3.weight torch.Size([1024])
layer3.0.bn3.bias torch.Size([1024])
layer3.0.bn3.running_mean torch.Size([1024])
layer3.0.bn3.running_var torch.Size([1024])
layer3.0.bn3.num_batches_tracked torch.Size([])
layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])
layer3.0.downsample.1.weight torch.Size([1024])
layer3.0.downsample.1.bias torch.Size([1024])
layer3.0.downsample.1.running_mean torch.Size([1024])
layer3.0.downsample.1.running_var torch.Size([1024])
layer3.0.downsample.1.num_batches_tracked torch.Size([])
layer3.0.bn1_skip.weight torch.Size([256])
layer3.0.bn1_skip.bias torch.Size([256])
layer3.0.bn1_skip.running_mean torch.Size([256])
layer3.0.bn1_skip.running_var torch.Size([256])
layer3.0.bn1_skip.num_batches_tracked torch.Size([])
layer3.0.bn2_skip.weight torch.Size([256])
layer3.0.bn2_skip.bias torch.Size([256])
layer3.0.bn2_skip.running_mean torch.Size([256])
layer3.0.bn2_skip.running_var torch.Size([256])
layer3.0.bn2_skip.num_batches_tracked torch.Size([])
layer3.0.bn3_skip.weight torch.Size([1024])
layer3.0.bn3_skip.bias torch.Size([1024])
layer3.0.bn3_skip.running_mean torch.Size([1024])
layer3.0.bn3_skip.running_var torch.Size([1024])
layer3.0.bn3_skip.num_batches_tracked torch.Size([])
layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])
layer3.1.bn1.weight torch.Size([256])
layer3.1.bn1.bias torch.Size([256])
layer3.1.bn1.running_mean torch.Size([256])
layer3.1.bn1.running_var torch.Size([256])
layer3.1.bn1.num_batches_tracked torch.Size([])
layer3.1.conv2.weight torch.Size([256, 256, 3, 3])
layer3.1.bn2.weight torch.Size([256])
layer3.1.bn2.bias torch.Size([256])
layer3.1.bn2.running_mean torch.Size([256])
layer3.1.bn2.running_var torch.Size([256])
layer3.1.bn2.num_batches_tracked torch.Size([])
layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])
layer3.1.bn3.weight torch.Size([1024])
layer3.1.bn3.bias torch.Size([1024])
layer3.1.bn3.running_mean torch.Size([1024])
layer3.1.bn3.running_var torch.Size([1024])
layer3.1.bn3.num_batches_tracked torch.Size([])
layer3.1.bn1_skip.weight torch.Size([256])
layer3.1.bn1_skip.bias torch.Size([256])
layer3.1.bn1_skip.running_mean torch.Size([256])
layer3.1.bn1_skip.running_var torch.Size([256])
layer3.1.bn1_skip.num_batches_tracked torch.Size([])
layer3.1.bn2_skip.weight torch.Size([256])
layer3.1.bn2_skip.bias torch.Size([256])
layer3.1.bn2_skip.running_mean torch.Size([256])
layer3.1.bn2_skip.running_var torch.Size([256])
layer3.1.bn2_skip.num_batches_tracked torch.Size([])
layer3.1.bn3_skip.weight torch.Size([1024])
layer3.1.bn3_skip.bias torch.Size([1024])
layer3.1.bn3_skip.running_mean torch.Size([1024])
layer3.1.bn3_skip.running_var torch.Size([1024])
layer3.1.bn3_skip.num_batches_tracked torch.Size([])
layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])
layer3.2.bn1.weight torch.Size([256])
layer3.2.bn1.bias torch.Size([256])
layer3.2.bn1.running_mean torch.Size([256])
layer3.2.bn1.running_var torch.Size([256])
layer3.2.bn1.num_batches_tracked torch.Size([])
layer3.2.conv2.weight torch.Size([256, 256, 3, 3])
layer3.2.bn2.weight torch.Size([256])
layer3.2.bn2.bias torch.Size([256])
layer3.2.bn2.running_mean torch.Size([256])
layer3.2.bn2.running_var torch.Size([256])
layer3.2.bn2.num_batches_tracked torch.Size([])
layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])
layer3.2.bn3.weight torch.Size([1024])
layer3.2.bn3.bias torch.Size([1024])
layer3.2.bn3.running_mean torch.Size([1024])
layer3.2.bn3.running_var torch.Size([1024])
layer3.2.bn3.num_batches_tracked torch.Size([])
layer3.2.bn1_skip.weight torch.Size([256])
layer3.2.bn1_skip.bias torch.Size([256])
layer3.2.bn1_skip.running_mean torch.Size([256])
layer3.2.bn1_skip.running_var torch.Size([256])
layer3.2.bn1_skip.num_batches_tracked torch.Size([])
layer3.2.bn2_skip.weight torch.Size([256])
layer3.2.bn2_skip.bias torch.Size([256])
layer3.2.bn2_skip.running_mean torch.Size([256])
layer3.2.bn2_skip.running_var torch.Size([256])
layer3.2.bn2_skip.num_batches_tracked torch.Size([])
layer3.2.bn3_skip.weight torch.Size([1024])
layer3.2.bn3_skip.bias torch.Size([1024])
layer3.2.bn3_skip.running_mean torch.Size([1024])
layer3.2.bn3_skip.running_var torch.Size([1024])
layer3.2.bn3_skip.num_batches_tracked torch.Size([])
layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])
layer3.3.bn1.weight torch.Size([256])
layer3.3.bn1.bias torch.Size([256])
layer3.3.bn1.running_mean torch.Size([256])
layer3.3.bn1.running_var torch.Size([256])
layer3.3.bn1.num_batches_tracked torch.Size([])
layer3.3.conv2.weight torch.Size([256, 256, 3, 3])
layer3.3.bn2.weight torch.Size([256])
layer3.3.bn2.bias torch.Size([256])
layer3.3.bn2.running_mean torch.Size([256])
layer3.3.bn2.running_var torch.Size([256])
layer3.3.bn2.num_batches_tracked torch.Size([])
layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])
layer3.3.bn3.weight torch.Size([1024])
layer3.3.bn3.bias torch.Size([1024])
layer3.3.bn3.running_mean torch.Size([1024])
layer3.3.bn3.running_var torch.Size([1024])
layer3.3.bn3.num_batches_tracked torch.Size([])
layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])
layer3.4.bn1.weight torch.Size([256])
layer3.4.bn1.bias torch.Size([256])
layer3.4.bn1.running_mean torch.Size([256])
layer3.4.bn1.running_var torch.Size([256])
layer3.4.bn1.num_batches_tracked torch.Size([])
layer3.4.conv2.weight torch.Size([256, 256, 3, 3])
layer3.4.bn2.weight torch.Size([256])
layer3.4.bn2.bias torch.Size([256])
layer3.4.bn2.running_mean torch.Size([256])
layer3.4.bn2.running_var torch.Size([256])
layer3.4.bn2.num_batches_tracked torch.Size([])
layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])
layer3.4.bn3.weight torch.Size([1024])
layer3.4.bn3.bias torch.Size([1024])
layer3.4.bn3.running_mean torch.Size([1024])
layer3.4.bn3.running_var torch.Size([1024])
layer3.4.bn3.num_batches_tracked torch.Size([])
layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])
layer3.5.bn1.weight torch.Size([256])
layer3.5.bn1.bias torch.Size([256])
layer3.5.bn1.running_mean torch.Size([256])
layer3.5.bn1.running_var torch.Size([256])
layer3.5.bn1.num_batches_tracked torch.Size([])
layer3.5.conv2.weight torch.Size([256, 256, 3, 3])
layer3.5.bn2.weight torch.Size([256])
layer3.5.bn2.bias torch.Size([256])
layer3.5.bn2.running_mean torch.Size([256])
layer3.5.bn2.running_var torch.Size([256])
layer3.5.bn2.num_batches_tracked torch.Size([])
layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])
layer3.5.bn3.weight torch.Size([1024])
layer3.5.bn3.bias torch.Size([1024])
layer3.5.bn3.running_mean torch.Size([1024])
layer3.5.bn3.running_var torch.Size([1024])
layer3.5.bn3.num_batches_tracked torch.Size([])
layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])
layer4.0.bn1.weight torch.Size([512])
layer4.0.bn1.bias torch.Size([512])
layer4.0.bn1.running_mean torch.Size([512])
layer4.0.bn1.running_var torch.Size([512])
layer4.0.bn1.num_batches_tracked torch.Size([])
layer4.0.conv2.weight torch.Size([512, 512, 3, 3])
layer4.0.bn2.weight torch.Size([512])
layer4.0.bn2.bias torch.Size([512])
layer4.0.bn2.running_mean torch.Size([512])
layer4.0.bn2.running_var torch.Size([512])
layer4.0.bn2.num_batches_tracked torch.Size([])
layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])
layer4.0.bn3.weight torch.Size([2048])
layer4.0.bn3.bias torch.Size([2048])
layer4.0.bn3.running_mean torch.Size([2048])
layer4.0.bn3.running_var torch.Size([2048])
layer4.0.bn3.num_batches_tracked torch.Size([])
layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])
layer4.0.downsample.1.weight torch.Size([2048])
layer4.0.downsample.1.bias torch.Size([2048])
layer4.0.downsample.1.running_mean torch.Size([2048])
layer4.0.downsample.1.running_var torch.Size([2048])
layer4.0.downsample.1.num_batches_tracked torch.Size([])
layer4.0.bn1_skip.weight torch.Size([512])
layer4.0.bn1_skip.bias torch.Size([512])
layer4.0.bn1_skip.running_mean torch.Size([512])
layer4.0.bn1_skip.running_var torch.Size([512])
layer4.0.bn1_skip.num_batches_tracked torch.Size([])
layer4.0.bn2_skip.weight torch.Size([512])
layer4.0.bn2_skip.bias torch.Size([512])
layer4.0.bn2_skip.running_mean torch.Size([512])
layer4.0.bn2_skip.running_var torch.Size([512])
layer4.0.bn2_skip.num_batches_tracked torch.Size([])
layer4.0.bn3_skip.weight torch.Size([2048])
layer4.0.bn3_skip.bias torch.Size([2048])
layer4.0.bn3_skip.running_mean torch.Size([2048])
layer4.0.bn3_skip.running_var torch.Size([2048])
layer4.0.bn3_skip.num_batches_tracked torch.Size([])
layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])
layer4.1.bn1.weight torch.Size([512])
layer4.1.bn1.bias torch.Size([512])
layer4.1.bn1.running_mean torch.Size([512])
layer4.1.bn1.running_var torch.Size([512])
layer4.1.bn1.num_batches_tracked torch.Size([])
layer4.1.conv2.weight torch.Size([512, 512, 3, 3])
layer4.1.bn2.weight torch.Size([512])
layer4.1.bn2.bias torch.Size([512])
layer4.1.bn2.running_mean torch.Size([512])
layer4.1.bn2.running_var torch.Size([512])
layer4.1.bn2.num_batches_tracked torch.Size([])
layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])
layer4.1.bn3.weight torch.Size([2048])
layer4.1.bn3.bias torch.Size([2048])
layer4.1.bn3.running_mean torch.Size([2048])
layer4.1.bn3.running_var torch.Size([2048])
layer4.1.bn3.num_batches_tracked torch.Size([])
layer4.1.bn1_skip.weight torch.Size([512])
layer4.1.bn1_skip.bias torch.Size([512])
layer4.1.bn1_skip.running_mean torch.Size([512])
layer4.1.bn1_skip.running_var torch.Size([512])
layer4.1.bn1_skip.num_batches_tracked torch.Size([])
layer4.1.bn2_skip.weight torch.Size([512])
layer4.1.bn2_skip.bias torch.Size([512])
layer4.1.bn2_skip.running_mean torch.Size([512])
layer4.1.bn2_skip.running_var torch.Size([512])
layer4.1.bn2_skip.num_batches_tracked torch.Size([])
layer4.1.bn3_skip.weight torch.Size([2048])
layer4.1.bn3_skip.bias torch.Size([2048])
layer4.1.bn3_skip.running_mean torch.Size([2048])
layer4.1.bn3_skip.running_var torch.Size([2048])
layer4.1.bn3_skip.num_batches_tracked torch.Size([])
layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])
layer4.2.bn1.weight torch.Size([512])
layer4.2.bn1.bias torch.Size([512])
layer4.2.bn1.running_mean torch.Size([512])
layer4.2.bn1.running_var torch.Size([512])
layer4.2.bn1.num_batches_tracked torch.Size([])
layer4.2.conv2.weight torch.Size([512, 512, 3, 3])
layer4.2.bn2.weight torch.Size([512])
layer4.2.bn2.bias torch.Size([512])
layer4.2.bn2.running_mean torch.Size([512])
layer4.2.bn2.running_var torch.Size([512])
layer4.2.bn2.num_batches_tracked torch.Size([])
layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])
layer4.2.bn3.weight torch.Size([2048])
layer4.2.bn3.bias torch.Size([2048])
layer4.2.bn3.running_mean torch.Size([2048])
layer4.2.bn3.running_var torch.Size([2048])
layer4.2.bn3.num_batches_tracked torch.Size([])
fc.weight torch.Size([1000, 2048])
fc.bias torch.Size([1000])
model : RetinaNet(
  (backbone): BackboneWithFPN(
    (body): IntermediateLayerGetter(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): FrozenBatchNorm2d(64, eps=1e-05)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(64, eps=1e-05)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(64, eps=1e-05)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(256, eps=1e-05)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): FrozenBatchNorm2d(256, eps=1e-05)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(64, eps=1e-05)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(64, eps=1e-05)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(256, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(64, eps=1e-05)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(64, eps=1e-05)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(256, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(128, eps=1e-05)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(128, eps=1e-05)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(512, eps=1e-05)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d(512, eps=1e-05)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(128, eps=1e-05)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(128, eps=1e-05)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(512, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(128, eps=1e-05)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(128, eps=1e-05)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(512, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(128, eps=1e-05)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(128, eps=1e-05)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(512, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d(1024, eps=1e-05)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(512, eps=1e-05)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(512, eps=1e-05)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d(2048, eps=1e-05)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(512, eps=1e-05)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(512, eps=1e-05)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(512, eps=1e-05)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(512, eps=1e-05)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (fpn): FeaturePyramidNetwork(
      (inner_blocks): ModuleList(
        (0): Conv2dNormActivation(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (layer_blocks): ModuleList(
        (0-2): 3 x Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (extra_blocks): LastLevelP6P7(
        (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
  )
  (anchor_generator): AnchorGenerator()
  (head): RetinaNetHead(
    (classification_head): RetinaNetClassificationHead(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
      )
      (cls_logits): Conv2d(256, 819, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (regression_head): RetinaNetRegressionHead(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
      )
      (bbox_reg): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (transform): GeneralizedRCNNTransform(
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
      Resize(min_size=(800,), max_size=1333, mode='bilinear')
  )
)
Start training
Epoch: [0]  [   0/7329]  eta: 3:33:46  lr: 0.000020  loss: 2.1885 (2.1885)  bbox_regression: 0.8273 (0.8273)  classification: 1.3612 (1.3612)  time: 1.7501  data: 0.7212  max mem: 5754
